from notion_client import Client
from datetime import datetime, timedelta
import logging
from config import NOTION_TOKEN, NOTION_DATABASE_ID, NOTION_TODO_DATABASE_ID, NOTION_PAPERS_DATABASE_ID
from utils.helpers import truncate_text
from services.gemini_service import analyze_content
import re
import os
import requests
import tempfile

logger = logging.getLogger(__name__)

# åˆå§‹åŒ– Notion å®¢æˆ·ç«¯
notion = Client(auth=NOTION_TOKEN)

# æ·»åŠ è¿™ä¸ªå‡½æ•°ï¼Œè¿”å›å·²åˆå§‹åŒ–çš„ notion å®¢æˆ·ç«¯
def get_notion_client():
    """
    è·å–å·²åˆå§‹åŒ–çš„ Notion å®¢æˆ·ç«¯
    
    è¿”å›ï¼š
        Client: Notion å®¢æˆ·ç«¯å®ä¾‹
    """
    global notion
    return notion

# å¯¼å…¥ Gemini æœåŠ¡
try:
    from services.gemini_service import analyze_pdf_content
    GEMINI_AVAILABLE = True
except ImportError:
    logger.warning("æ— æ³•å¯¼å…¥ Gemini æœåŠ¡ï¼Œå°†ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è§£æ PDF")
    GEMINI_AVAILABLE = False

def add_to_notion(content, summary, tags, url="", created_at=None):
    """
    å°†å†…å®¹æ·»åŠ åˆ° Notion æ•°æ®åº“
    
    å‚æ•°ï¼š
    content (str): æ¶ˆæ¯å†…å®¹
    summary (str): AI ç”Ÿæˆçš„æ‘˜è¦
    tags (list): AI ç”Ÿæˆçš„æ ‡ç­¾åˆ—è¡¨
    url (str): å¯é€‰çš„ URL
    created_at (datetime): åˆ›å»ºæ—¶é—´
    
    è¿”å›ï¼š
    str: åˆ›å»ºçš„é¡µé¢ ID
    """
    if not created_at:
        created_at = datetime.now()
    
    # æ³¨é‡Šæ‰è¿™éƒ¨åˆ†ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»åœ¨ telegram_service.py ä¸­å¤„ç†äº† PDF URL
    # æ£€æŸ¥ URL æ˜¯å¦æ˜¯ PDF æ–‡ä»¶
    # if url and is_pdf_url(url):
    #     logger.info(f"æ£€æµ‹åˆ° PDF URL: {url}ï¼Œå°†æŒ‰ç…§å­¦æœ¯è®ºæ–‡è§£æ")
    #     try:
    #         # ä¸‹è½½ PDF æ–‡ä»¶ç”¨äºè§£æ
    #         pdf_path, _ = download_pdf(url)
    #         if pdf_path:
    #             ... åŸæœ‰ PDF å¤„ç†é€»è¾‘ ...
    
    # ç¡®å®šé¡µé¢æ ‡é¢˜
    title = determine_title(content, url, summary)
    
    # å‡†å¤‡æ ‡ç­¾æ ¼å¼
    tag_objects = []
    for tag in tags:
        tag_objects.append({"name": tag})
    
    # å°†å†…å®¹è½¬æ¢ä¸º Notion å—æ ¼å¼
    content_blocks = convert_to_notion_blocks(content)
    
    # é™åˆ¶å—æ•°é‡ï¼Œç¡®ä¿ä¸è¶…è¿‡ Notion API é™åˆ¶
    content_blocks = limit_blocks(content_blocks)
    # æˆªæ–­æ‘˜è¦ï¼Œç¡®ä¿ä¸è¶…è¿‡ 2000 ä¸ªå­—ç¬¦
    truncated_summary = summary[:2000] if summary else ""
    
    # åˆ›å»º Notion é¡µé¢
    try:
        new_page = notion.pages.create(
            parent={"database_id": NOTION_DATABASE_ID},
            properties={
                "Name": {
                    "title": [
                        {
                            "text": {
                                "content": title
                            }
                        }
                    ]
                },
                "Summary": {
                    "rich_text": [
                        {
                            "text": {
                                "content": truncated_summary
                            }
                        }
                    ]
                },
                "Tags": {
                    "multi_select": tag_objects
                },
                "URL": {
                    "url": url if url else None
                },
                "Created": {
                    "date": {
                        "start": created_at.isoformat()
                    }
                }
            },
            children=content_blocks
        )
        logger.info(f"æˆåŠŸåˆ›å»º Notion é¡µé¢ï¼š{new_page['id']}")
        return new_page['id']
    
    except Exception as e:
        logger.error(f"åˆ›å»º Notion é¡µé¢æ—¶å‡ºé”™ï¼š{e}")
        raise

def convert_to_notion_blocks(content):
    """
    å°†æ–‡æœ¬å†…å®¹è½¬æ¢ä¸º Notion å—æ ¼å¼ï¼Œæ”¯æŒ Markdown è¯­æ³•
    
    å‚æ•°ï¼š
    content (str): è¦è½¬æ¢çš„æ–‡æœ¬å†…å®¹
    
    è¿”å›ï¼š
    list: Notion å—å¯¹è±¡åˆ—è¡¨
    """
    import re
    
    # Notion API æ–‡æœ¬å—é•¿åº¦é™åˆ¶
    MAX_TEXT_LENGTH = 2000
    
    # å¦‚æœå†…å®¹ä¸ºç©ºï¼Œè¿”å›ç®€å•æ®µè½
    if not content or len(content.strip()) == 0:
        return [
            {
                "object": "block",
                "paragraph": {
                    "rich_text": [{"text": {"content": ""}}]
                }
            }
        ]
    
    # å°†å†…å®¹åˆ†æˆè¡Œ
    lines = content.split("\n")
    blocks = []
    
    i = 0
    current_list_type = None  # 'bulleted' æˆ– 'numbered'
    list_levels = []  # ä¿å­˜å½“å‰å±‚çº§çš„åˆ—è¡¨é¡¹ä¿¡æ¯
    
    while i < len(lines):
        line = lines[i].strip()
        
        # å¤„ç†æ ‡é¢˜ (# æ ‡é¢˜)
        header_match = re.match(r'^(#{1,3})\s+(.+)$', line)
        if header_match:
            # å¦‚æœä¹‹å‰åœ¨å¤„ç†åˆ—è¡¨ï¼Œç»“æŸåˆ—è¡¨
            current_list_type = None
            list_levels = []
            
            level = len(header_match.group(1))
            heading_text = header_match.group(2)
            
            # ç¡®ä¿æ ‡é¢˜æ–‡æœ¬ä¸è¶…è¿‡é™åˆ¶
            if len(heading_text) > MAX_TEXT_LENGTH:
                heading_text = heading_text[:MAX_TEXT_LENGTH-3] + "..."
            
            heading_type = f"heading_{level}"
            blocks.append({
                "object": "block",
                heading_type: {
                    "rich_text": parse_markdown_formatting(heading_text)
                }
            })
            i += 1
            continue
        
        # å¤„ç†åˆ—è¡¨é¡¹ï¼Œæ”¯æŒå¤šçº§åˆ—è¡¨
        # æ£€æŸ¥åˆ—è¡¨é¡¹çš„ç¼©è¿›çº§åˆ«
        list_match = re.match(r'^(\s*)[-*]\s+(.+)$', line)
        if list_match:
            indent = len(list_match.group(1))
            list_text = list_match.group(2)
            
            # ç¡®å®šåˆ—è¡¨çº§åˆ« (åŸºäºç¼©è¿›)
            indent_level = indent // 2  # å‡è®¾æ¯çº§ç¼©è¿›ä¸º 2 ä¸ªç©ºæ ¼
            
            # æ›´æ–°åˆ—è¡¨çº§åˆ«ä¿¡æ¯
            if current_list_type != 'bulleted' or indent_level != len(list_levels):
                # æ–°çš„åˆ—è¡¨ç±»å‹æˆ–æ–°çš„ç¼©è¿›çº§åˆ«
                current_list_type = 'bulleted'
                
                # è°ƒæ•´ list_levels ä»¥åŒ¹é…å½“å‰çº§åˆ«
                if indent_level > len(list_levels):
                    # å¢åŠ ç¼©è¿›çº§åˆ«
                    while len(list_levels) < indent_level:
                        list_levels.append('bulleted')
                else:
                    # å‡å°‘ç¼©è¿›çº§åˆ«
                    list_levels = list_levels[:indent_level]
                list_levels.append('bulleted')
            
            # åˆ†å‰²é•¿åˆ—è¡¨é¡¹
            for chunk in split_text(list_text, MAX_TEXT_LENGTH):
                # æ ¹æ®ç¼©è¿›çº§åˆ«åˆ›å»ºåµŒå¥—ç»“æ„
                block = {
                    "object": "block",
                    "bulleted_list_item": {
                        "rich_text": parse_markdown_formatting(chunk)
                    }
                }
                
                # å¤„ç†å­é¡¹
                if indent_level > 0:
                    # æ·»åŠ ç¼©è¿›ä¿¡æ¯
                    block["bulleted_list_item"]["color"] = "default"
                
                blocks.append(block)
            i += 1
            continue
        
        # å¤„ç†æ•°å­—åˆ—è¡¨é¡¹ï¼Œæ”¯æŒå¤šçº§åˆ—è¡¨
        num_list_match = re.match(r'^(\s*)(\d+)\.\s+(.+)$', line)
        if num_list_match:
            indent = len(num_list_match.group(1))
            num = num_list_match.group(2)
            list_text = num_list_match.group(3)
            
            # ç¡®å®šåˆ—è¡¨çº§åˆ« (åŸºäºç¼©è¿›)
            indent_level = indent // 2  # å‡è®¾æ¯çº§ç¼©è¿›ä¸º 2 ä¸ªç©ºæ ¼
            
            # æ›´æ–°åˆ—è¡¨çº§åˆ«ä¿¡æ¯
            if current_list_type != 'numbered' or indent_level != len(list_levels):
                current_list_type = 'numbered'
                
                # è°ƒæ•´ list_levels ä»¥åŒ¹é…å½“å‰çº§åˆ«
                if indent_level > len(list_levels):
                    # å¢åŠ ç¼©è¿›çº§åˆ«
                    while len(list_levels) < indent_level:
                        list_levels.append('numbered')
                else:
                    # å‡å°‘ç¼©è¿›çº§åˆ«
                    list_levels = list_levels[:indent_level]
                list_levels.append('numbered')
            
            # åˆ†å‰²é•¿åˆ—è¡¨é¡¹
            for chunk in split_text(list_text, MAX_TEXT_LENGTH):
                # åˆ›å»ºç¼–å·åˆ—è¡¨é¡¹
                block = {
                    "object": "block",
                    "numbered_list_item": {
                        "rich_text": parse_markdown_formatting(chunk)
                    }
                }
                
                # å¤„ç†å­é¡¹
                if indent_level > 0:
                    # æ·»åŠ ç¼©è¿›ä¿¡æ¯
                    block["numbered_list_item"]["color"] = "default"
                
                blocks.append(block)
            i += 1
            continue
        
        # å¦‚æœé‡åˆ°ç©ºè¡Œæˆ–å…¶ä»–éåˆ—è¡¨é¡¹ï¼Œé‡ç½®åˆ—è¡¨çŠ¶æ€
        if not line:
            current_list_type = None
            list_levels = []
        
        # å¤„ç†å¼•ç”¨å— (> å¼•ç”¨)
        quote_match = re.match(r'^>\s+(.+)$', line)
        if quote_match:
            # ç»“æŸä¹‹å‰çš„åˆ—è¡¨
            current_list_type = None
            list_levels = []
            
            quote_text = quote_match.group(1)
            
            # åˆ†å‰²é•¿å¼•ç”¨
            for chunk in split_text(quote_text, MAX_TEXT_LENGTH):
                blocks.append({
                    "object": "block",
                    "quote": {
                        "rich_text": parse_markdown_formatting(chunk)
                    }
                })
            i += 1
            continue
        
        # å¤„ç†ä»£ç å— (```language ä»£ç  ```)
        if line.startswith("```"):
            # ç»“æŸä¹‹å‰çš„åˆ—è¡¨
            current_list_type = None
            list_levels = []
            
            code_lang = line[3:].strip()
            code_content = []
            i += 1
            
            while i < len(lines) and not lines[i].strip().endswith("```"):
                code_content.append(lines[i])
                i += 1
            
            if i < len(lines):  # æ‰¾åˆ°äº†ç»“æŸæ ‡è®°
                code_text = "\n".join(code_content)
                blocks.append({
                    "object": "block",
                    "code": {
                        "language": code_lang if code_lang else "plain text",
                        "rich_text": [{"text": {"content": code_text}}]
                    }
                })
                i += 1
                continue
        
        # å¤„ç†è¡¨æ ¼è¡Œ (| åˆ— 1 | åˆ— 2 | åˆ— 3 |)
        table_match = re.match(r'^\s*\|(.+)\|\s*$', line)
        if table_match:
            # æ£€æµ‹åˆ°è¡¨æ ¼ï¼Œä½† Notion API å½“å‰æœ‰ä¸€äº›é™åˆ¶ï¼Œæˆ‘ä»¬å…ˆè·³è¿‡å®ƒ
            # åœ¨æœªæ¥çš„ç‰ˆæœ¬å¯ä»¥å¤„ç†è¡¨æ ¼è½¬æ¢
            current_list_type = None
            list_levels = []
            
            # æå–è¡¨æ ¼è¡Œçš„å†…å®¹
            cells = [cell.strip() for cell in table_match.group(1).split('|')]
            
            # æŠŠè¡¨æ ¼è¡Œè½¬ä¸ºæ™®é€šæ–‡æœ¬
            table_line = "| " + " | ".join(cells) + " |"
            blocks.append({
                "object": "block",
                "paragraph": {
                    "rich_text": [{"text": {"content": table_line}}]
                }
            })
            i += 1
            continue
        
        # å¤„ç†æ™®é€šæ®µè½
        if line:
            # ç»“æŸä¹‹å‰çš„åˆ—è¡¨
            current_list_type = None
            list_levels = []
            
            # åˆ†å‰²é•¿æ®µè½
            for chunk in split_text(line, MAX_TEXT_LENGTH):
                blocks.append({
                    "object": "block",
                    "paragraph": {
                        "rich_text": parse_markdown_formatting(chunk)
                    }
                })
        else:
            # ç©ºè¡Œï¼Œæ·»åŠ ç©ºæ®µè½
            blocks.append({
                "object": "block",
                "paragraph": {
                    "rich_text": []
                }
            })
        
        i += 1
    
    return blocks

def limit_blocks(blocks, max_blocks=100):
    """
    é™åˆ¶ Notion å—çš„æ•°é‡å’Œå†…å®¹é•¿åº¦ï¼Œç¡®ä¿ä¸è¶…è¿‡ API é™åˆ¶
    
    å‚æ•°ï¼š
    blocks (list): Notion å—åˆ—è¡¨
    max_blocks (int): æœ€å¤§å—æ•°é‡ï¼Œé»˜è®¤ä¸º 100ï¼ˆNotion API é™åˆ¶ï¼‰
    
    è¿”å›ï¼š
    list: é™åˆ¶åçš„å—åˆ—è¡¨
    """
    if not blocks:
        return []
        
    MAX_TEXT_LENGTH = 2000  # Notion API æ–‡æœ¬é•¿åº¦é™åˆ¶
    limited_blocks = []
    blocks_processed = 0
    
    # ç•™å‡ºä¸€ä¸ªä½ç½®ç»™å¯èƒ½çš„æˆªæ–­æç¤ºå—
    actual_max_blocks = max_blocks - 1
    
    # å¤„ç†æ‰€æœ‰å—ï¼Œç¡®ä¿æ¯ä¸ªå—çš„å†…å®¹ä¸è¶…è¿‡é™åˆ¶
    for block in blocks:
        # å¦‚æœå·²ç»å¤„ç†äº†æœ€å¤§æ•°é‡çš„å—ï¼Œç›´æ¥é€€å‡ºå¾ªç¯
        if len(limited_blocks) >= actual_max_blocks:
            logger.warning(f"è¾¾åˆ°æœ€å¤§å—é™åˆ¶ ({actual_max_blocks})ï¼Œåœæ­¢å¤„ç†å…¶ä½™ {len(blocks) - blocks_processed} ä¸ªå—")
            break
            
        blocks_processed += 1
        block_type = block.get("object", "block")
        
        # å¤„ç†ä¸åŒç±»å‹çš„å—
        if block_type == "block":
            # è·å–å—ç±»å‹ï¼ˆparagraph, heading_x, code ç­‰ï¼‰
            content_type = list(block.keys())[0] if block else None
            if not content_type or content_type == "object":
                content_type = list(block.keys())[1] if len(block.keys()) > 1 else None
            
            if content_type:
                # å¤„ç†ä»£ç å—ï¼ˆç‰¹åˆ«éœ€è¦æ³¨æ„ï¼Œå› ä¸ºå®ƒä»¬é€šå¸¸åŒ…å«è¾ƒé•¿æ–‡æœ¬ï¼‰
                if content_type == "code" and "rich_text" in block["code"]:
                    code_content = ""
                    if block["code"]["rich_text"] and "text" in block["code"]["rich_text"][0]:
                        code_content = block["code"]["rich_text"][0]["text"].get("content", "")
                    
                    # å¦‚æœä»£ç å†…å®¹è¶…å‡ºé™åˆ¶ï¼Œåˆ†å‰²æˆå¤šä¸ªä»£ç å—
                    if len(code_content) > MAX_TEXT_LENGTH:
                        language = block["code"].get("language", "plain text")
                        # åˆ†å‰²ä»£ç å†…å®¹
                        code_chunks = []
                        for i in range(0, len(code_content), MAX_TEXT_LENGTH):
                            chunk = code_content[i:i+MAX_TEXT_LENGTH]
                            code_chunks.append({
                                "object": "block",
                                "code": {
                                    "language": language,
                                    "rich_text": [{"text": {"content": chunk}}]
                                }
                            })
                        
                        # ç¡®ä¿æ·»åŠ çš„ä»£ç å—ä¸ä¼šè¶…è¿‡é™åˆ¶
                        remaining_slots = actual_max_blocks - len(limited_blocks)
                        if len(code_chunks) > remaining_slots:
                            limited_blocks.extend(code_chunks[:remaining_slots])
                            logger.warning(f"ä»£ç å—è¿‡é•¿ï¼Œåªä¿ç•™äº†å‰ {remaining_slots} ä¸ªä»£ç å—")
                            break  # é€€å‡ºå¾ªç¯ï¼Œæ·»åŠ æˆªæ–­æç¤º
                        else:
                            limited_blocks.extend(code_chunks)
                    else:
                        limited_blocks.append(block)
                
                # å¤„ç†æ®µè½ã€æ ‡é¢˜å’Œå…¶ä»–æ–‡æœ¬å—
                elif content_type in ["paragraph", "heading_1", "heading_2", "heading_3", 
                                    "bulleted_list_item", "numbered_list_item", "quote", "callout"]:
                    rich_text_key = content_type
                    if rich_text_key in block and "rich_text" in block[rich_text_key]:
                        rich_texts = block[rich_text_key]["rich_text"]
                        
                        # è®¡ç®—æ€»æ–‡æœ¬é•¿åº¦
                        total_length = sum(len(rt.get("text", {}).get("content", "")) for rt in rich_texts if "text" in rt)
                        
                        if total_length > MAX_TEXT_LENGTH:
                            # å¦‚æœæ€»é•¿åº¦è¶…å‡ºé™åˆ¶ï¼Œåˆ›å»ºæ–°çš„ç®€åŒ–æ–‡æœ¬å—
                            combined_text = "".join(rt.get("text", {}).get("content", "") for rt in rich_texts if "text" in rt)
                            text_chunks = []
                            
                            # åˆ†å‰²æ–‡æœ¬å¹¶åˆ›å»ºå¤šä¸ªå—
                            for i in range(0, len(combined_text), MAX_TEXT_LENGTH):
                                chunk = combined_text[i:i+MAX_TEXT_LENGTH]
                                new_block = {
                                    "object": "block",
                                    content_type: {
                                        "rich_text": [{"text": {"content": chunk}}]
                                    }
                                }
                                
                                # ä¿ç•™åŸå§‹å—çš„å…¶ä»–å±æ€§ï¼ˆå¦‚é¢œè‰²ï¼‰
                                for key, value in block[content_type].items():
                                    if key != "rich_text":
                                        new_block[content_type][key] = value
                                        
                                text_chunks.append(new_block)
                            
                            # ç¡®ä¿æ·»åŠ çš„æ–‡æœ¬å—ä¸ä¼šè¶…è¿‡é™åˆ¶
                            remaining_slots = actual_max_blocks - len(limited_blocks)
                            if len(text_chunks) > remaining_slots:
                                limited_blocks.extend(text_chunks[:remaining_slots])
                                logger.warning(f"æ–‡æœ¬å—è¿‡é•¿ï¼Œåªä¿ç•™äº†å‰ {remaining_slots} ä¸ªæ–‡æœ¬å—")
                                break  # é€€å‡ºå¾ªç¯ï¼Œæ·»åŠ æˆªæ–­æç¤º
                            else:
                                limited_blocks.extend(text_chunks)
                        else:
                            limited_blocks.append(block)
                else:
                    # å…¶ä»–ç±»å‹çš„å—ç›´æ¥æ·»åŠ 
                    limited_blocks.append(block)
            else:
                limited_blocks.append(block)
        else:
            limited_blocks.append(block)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ æˆªæ–­æç¤º
    if blocks_processed < len(blocks) or len(limited_blocks) >= actual_max_blocks:
        # ç¡®ä¿æˆ‘ä»¬å§‹ç»ˆæœ‰ç©ºé—´æ·»åŠ è­¦å‘Šå—
        if len(limited_blocks) >= max_blocks:
            # ç§»é™¤ä¸€ä¸ªå—æ¥è…¾å‡ºç©ºé—´
            limited_blocks.pop()
        
        # æ·»åŠ æˆªæ–­è­¦å‘Š
        limited_blocks.append({
            "object": "block",
            "callout": {
                "rich_text": [{"text": {"content": f"å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­æ˜¾ç¤º ({len(limited_blocks)} / {len(blocks)} å—)ã€‚å®Œæ•´å†…å®¹è¯·å‚è€ƒåŸå§‹æ–‡æ¡£ã€‚"}}],
                "icon": {"emoji": "âš ï¸"},
                "color": "yellow_background"
            }
        })
        
        logger.warning(f"å†…å®¹è¿‡å¤š ({len(blocks)} å—)ï¼Œå·²æˆªæ–­è‡³ {len(limited_blocks)} å—")
    
    # æœ€ç»ˆç¡®ä¿å—æ•°é‡ä¸è¶…è¿‡é™åˆ¶
    if len(limited_blocks) > max_blocks:
        logger.error(f"è‡´å‘½é”™è¯¯ï¼šé™åˆ¶åå—æ•°é‡ ({len(limited_blocks)}) ä»ç„¶è¶…è¿‡ Notion API é™åˆ¶ ({max_blocks})")
        return limited_blocks[:max_blocks]
    
    return limited_blocks

def parse_markdown_formatting(text):
    """
    è§£ææ–‡æœ¬ä¸­çš„ Markdown æ ¼å¼å¹¶è½¬æ¢ä¸º Notion rich_text æ ¼å¼
    
    æ”¯æŒï¼š
    - **åŠ ç²—**
    - *æ–œä½“*
    - ~~åˆ é™¤çº¿~~
    - `ä»£ç `
    - [é“¾æ¥](URL)
    - [å†…å®¹](https://notion.so/PAGE_ID) ä½œä¸º Notion é¡µé¢é“¾æ¥
    
    å‚æ•°ï¼š
    text (str): åŒ…å« Markdown æ ¼å¼çš„æ–‡æœ¬
    
    è¿”å›ï¼š
    list: Notion rich_text å¯¹è±¡åˆ—è¡¨
    """
    import re
    
    # å¦‚æœæ–‡æœ¬ä¸ºç©ºï¼Œè¿”å›ç©ºåˆ—è¡¨
    if not text:
        return []
    
    # åˆ›å»ºä¸€ä¸ªç»“æœåˆ—è¡¨
    result = []
    
    # ä½¿ç”¨ä¸€ä¸ªæ›´ç²¾ç¡®çš„æ–¹æ³•æ¥å¤„ç†æ ¼å¼åŒ–æ–‡æœ¬
    # 1. é¦–å…ˆè¯†åˆ«æ‰€æœ‰ç‰¹æ®Šæ ¼å¼çš„ä½ç½®å’Œç±»å‹
    formats = []
    
    # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
    patterns = [
        # Notion é¡µé¢é“¾æ¥ [text](https://notion.so/pageid)
        (r'\[(.+?)\]\(https://notion\.so/([a-zA-Z0-9]+)\)', 'notion_page'),
        # æ™®é€šé“¾æ¥ [text](url)
        (r'\[(.+?)\]\((?!https://notion\.so/)(.+?)\)', 'link'),
        # åŠ ç²— **text**
        (r'\*\*(.+?)\*\*', 'bold'),
        # æ–œä½“ *text*
        (r'\*(.+?)\*', 'italic'),
        # åˆ é™¤çº¿ ~~text~~
        (r'~~(.+?)~~', 'strikethrough'),
        # ä»£ç  `text`
        (r'`(.+?)`', 'code')
    ]
    
    # æŸ¥æ‰¾æ‰€æœ‰æ ¼å¼æ ‡è®°çš„ä½ç½®
    for pattern, format_type in patterns:
        for match in re.finditer(pattern, text):
            start, end = match.span()
            content = match.group(1)  # æ ¼å¼å†…çš„å®é™…æ–‡æœ¬
            
            # å¤„ç†ä¸åŒç±»å‹çš„é“¾æ¥
            if format_type == 'link':
                url = match.group(2)
                formats.append((start, end, format_type, content, url))
            elif format_type == 'notion_page':
                page_id = match.group(2)
                formats.append((start, end, format_type, content, page_id))
            else:
                formats.append((start, end, format_type, content, None))
    
    # 2. æŒ‰ç…§èµ·å§‹ä½ç½®æ’åºæ ¼å¼æ ‡è®°
    formats.sort(key=lambda x: x[0])
    
    # 3. å¤„ç†æ–‡æœ¬ï¼Œé¿å…é‡å¤
    if not formats:
        # æ²¡æœ‰æ ¼å¼ï¼Œç›´æ¥è¿”å›çº¯æ–‡æœ¬
        return [{"text": {"content": text}}]
    
    # å¤„ç†æœ‰æ ¼å¼çš„æ–‡æœ¬
    last_end = 0
    processed = []  # ç”¨æ¥è·Ÿè¸ªå·²å¤„ç†çš„æ–‡æœ¬èŒƒå›´
    
    for start, end, format_type, content, link_data in formats:
        # æ£€æŸ¥è¿™ä¸ªåŒºåŸŸæ˜¯å¦å·²è¢«å¤„ç†
        if any(s <= start < e or s < end <= e for s, e in processed):
            continue
        
        # æ·»åŠ æ ¼å¼æ ‡è®°å‰çš„æ™®é€šæ–‡æœ¬
        if start > last_end:
            plain_text = text[last_end:start]
            if plain_text:
                result.append({"text": {"content": plain_text}})
        
        # æ·»åŠ æ ¼å¼åŒ–æ–‡æœ¬
        if format_type == 'notion_page':
            # åˆ›å»ºé¡µé¢å¼•ç”¨/æåŠ
            result.append({
                "mention": {
                    "type": "page",
                    "page": {
                        "id": link_data
                    }
                },
                "plain_text": content,
                "href": f"https://notion.so/{link_data}"
            })
        else:
            # æ ‡å‡†æ–‡æœ¬æ ¼å¼
            rich_text = {
                "text": {"content": content}
            }
            
            if format_type == 'link' and url:
                rich_text["text"]["link"] = {"url": url}
            
            # è®¾ç½®æ–‡æœ¬çš„æ ¼å¼æ³¨é‡Š
            annotations = {"bold": False, "italic": False, "strikethrough": False, "code": False}
            if format_type in annotations:
                annotations[format_type] = True
            rich_text["annotations"] = annotations
            
            result.append(rich_text)
        
        # æ›´æ–°å·²å¤„ç†çš„èŒƒå›´
        processed.append((start, end))
        last_end = end
    
    # æ·»åŠ æœ€åä¸€æ®µæ™®é€šæ–‡æœ¬
    if last_end < len(text):
        result.append({"text": {"content": text[last_end:]}})
    
    return result

def split_text(text, max_length):
    """
    å°†æ–‡æœ¬åˆ†å‰²æˆä¸è¶…è¿‡æœ€å¤§é•¿åº¦çš„å—
    
    å‚æ•°ï¼š
    text (str): è¦åˆ†å‰²çš„æ–‡æœ¬
    max_length (int): æ¯å—çš„æœ€å¤§é•¿åº¦
    
    è¿”å›ï¼š
    list: æ–‡æœ¬å—åˆ—è¡¨
    """
    if len(text) <= max_length:
        return [text]
    
    chunks = []
    for i in range(0, len(text), max_length):
        # å¦‚æœä¸æ˜¯ç¬¬ä¸€å—ï¼Œå°½é‡åœ¨å¥å­æˆ–å•è¯è¾¹ç•Œåˆ†å‰²
        if i > 0 and i + max_length < len(text):
            # å°è¯•åœ¨å¥å­ç»“æŸå¤„åˆ†å‰²ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·åé¢ï¼‰
            end = min(i + max_length, len(text))
            break_point = max(text.rfind('. ', i, end), 
                             text.rfind('? ', i, end),
                             text.rfind('! ', i, end))
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¥å­ç»“æŸï¼Œå°è¯•åœ¨ç©ºæ ¼å¤„åˆ†å‰²
            if break_point < i:
                break_point = text.rfind(' ', i, end)
            
            # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åˆ†å‰²ç‚¹ï¼Œåˆ™å¼ºåˆ¶åœ¨æœ€å¤§é•¿åº¦å¤„åˆ†å‰²
            if break_point < i:
                break_point = i + max_length - 1
            else:
                # åŒ…å«åˆ†éš”ç¬¦
                break_point += 1
                
            chunks.append(text[i:break_point])
            i = break_point - 1  # å‡ 1 æ˜¯å› ä¸ºå¾ªç¯ä¼šåŠ å›æ¥
        else:
            chunks.append(text[i:i + max_length])
    
    return chunks

def determine_title(content, url, summary):
    """åŸºäºå†…å®¹ã€URL å’Œæ‘˜è¦ç¡®å®šæ ‡é¢˜"""
    # å¦‚æœå†…å®¹å¾ˆçŸ­ï¼Œç›´æ¥ä½¿ç”¨å†…å®¹ä½œä¸ºæ ‡é¢˜
    if len(content) <= 100:
        return content
    
    # å¦‚æœæœ‰ URL å’Œæ‘˜è¦ï¼Œä½¿ç”¨æ‘˜è¦çš„ç¬¬ä¸€å¥
    # if url and summary:
    #     first_sentence = summary.split(".")[0]
    #     # ç¡®ä¿æ ‡é¢˜é•¿åº¦ä¸è¶…è¿‡ 50 ä¸ªå­—ç¬¦
    #     if len(first_sentence) > 50:
    #         return first_sentence[:47] + "..."
    #     return first_sentence + "..."
    
    # é»˜è®¤ä½¿ç”¨å†…å®¹çš„å‰ä¸€éƒ¨åˆ†ä½œä¸ºæ ‡é¢˜
    return analyze_content(content)["title"]

def get_weekly_entries(days=7):
    """
    è·å–è¿‡å»å‡ å¤©å†…æ·»åŠ çš„æ‰€æœ‰æ¡ç›®
    
    å‚æ•°ï¼š
    days (int): è¦æ£€ç´¢çš„å¤©æ•°
    
    è¿”å›ï¼š
    list: Notion é¡µé¢å¯¹è±¡åˆ—è¡¨
    """
    from datetime import datetime, timedelta
    
    # è®¡ç®—æ—¥æœŸèŒƒå›´
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    # æŸ¥è¯¢ Notion æ•°æ®åº“
    try:
        response = notion.databases.query(
            database_id=NOTION_DATABASE_ID,
            filter={
                "and": [
                    {
                        "property": "Created",
                        "date": {
                            "on_or_after": start_date.isoformat()
                        }
                    }
                ]
            },
            sorts=[
                {
                    "property": "Created",
                    "direction": "ascending"
                }
            ]
        )
        
        return response["results"]
    
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ Notion æ•°æ®åº“æ—¶å‡ºé”™ï¼š{e}")
        raise

def create_weekly_report(title, content):
    """
    åˆ›å»ºå‘¨æŠ¥é¡µé¢
    
    å‚æ•°ï¼š
    title (str): å‘¨æŠ¥æ ‡é¢˜
    content (str): å‘¨æŠ¥å†…å®¹ï¼Œå¯ä»¥åŒ…å« [å¼•ç”¨æ–‡æœ¬](ref:é¡µé¢ ID) æ ¼å¼çš„å¼•ç”¨
    
    è¿”å›ï¼š
    str: åˆ›å»ºçš„é¡µé¢ URL
    """
    try:
        # å°†å†…å®¹ä¸­çš„å¼•ç”¨æ ¼å¼ [æ ‡é¢˜](ref:é¡µé¢ ID) è½¬æ¢ä¸º Notion å†…é“¾æ ¼å¼
        logger.info("å¤„ç†å‘¨æŠ¥ä¸­çš„é¡µé¢å¼•ç”¨...")
        processed_content = process_notion_references(content)
        
        # å°†å†…å®¹è½¬æ¢ä¸º Notion block æ ¼å¼ï¼Œæ”¯æŒå†…é“¾
        blocks = convert_to_notion_blocks(processed_content)
        
        # åˆ›å»ºé¡µé¢
        new_page = notion.pages.create(
            parent={"database_id": NOTION_DATABASE_ID},
            properties={
                "Name": {
                    "title": [
                        {
                            "text": {
                                "content": title
                            }
                        }
                    ]
                },
                "Tags": {
                    "multi_select": [{"name": "å‘¨æŠ¥"}]
                },
                "Created": {
                    "date": {
                        "start": datetime.now().isoformat()
                    }
                }
            },
            children=blocks
        )
        
        page_id = new_page['id']
        logger.info(f"æˆåŠŸåˆ›å»ºå‘¨æŠ¥é¡µé¢ï¼š{page_id}")
        
        # è¿”å›é¡µé¢ URL
        return f"https://notion.so/{page_id.replace('-', '')}"
    
    except Exception as e:
        logger.error(f"åˆ›å»ºå‘¨æŠ¥é¡µé¢æ—¶å‡ºé”™ï¼š{e}")
        raise

def process_notion_references(content):
    """
    å¤„ç†æ–‡æœ¬ä¸­çš„ Notion å¼•ç”¨æ ‡è®°ï¼Œè½¬æ¢ä¸º Notion é“¾æ¥æ ¼å¼
    æ”¯æŒæ ¼å¼ï¼š[å¼•ç”¨æ–‡æœ¬](ref:é¡µé¢ ID)
    
    å‚æ•°ï¼š
    content (str): åŒ…å« [å¼•ç”¨æ–‡æœ¬](ref:é¡µé¢ ID) æ ¼å¼å¼•ç”¨çš„æ–‡æœ¬
    
    è¿”å›ï¼š
    str: è½¬æ¢åçš„æ–‡æœ¬ï¼Œå¼•ç”¨è½¬ä¸º Notion å¯è¯†åˆ«çš„å†…é“¾æ ¼å¼
    """
    import re
    
    # æŸ¥æ‰¾æ ¼å¼ä¸º [å¼•ç”¨æ–‡æœ¬](ref:é¡µé¢ ID) çš„å¼•ç”¨
    pattern = r'\[(.*?)\]\(ref:([a-zA-Z0-9-]+)\)'
    
    def replace_ref(match):
        text = match.group(1)
        page_id = match.group(2)
        
        # è¿”å› Notion é¡µé¢é“¾æ¥æ ¼å¼ - è¿™ä¼šè¢« convert_to_notion_blocks å‡½æ•°è¿›ä¸€æ­¥å¤„ç†
        # ç¡®ä¿ ID æ ¼å¼æ­£ç¡®ï¼ˆç§»é™¤è¿å­—ç¬¦ï¼Œå› ä¸º Notion URL ä¸­ä¸ä½¿ç”¨ï¼‰
        clean_id = page_id.replace('-', '')
        return f"[{text}](https://notion.so/{clean_id})"
    
    # æ›¿æ¢æ‰€æœ‰åŒ¹é…é¡¹
    processed_text = re.sub(pattern, replace_ref, content)
    
    # è®°å½•å¤„ç†æƒ…å†µ
    original_refs_count = len(re.findall(pattern, content))
    processed_refs_count = len(re.findall(r'\[(.*?)\]\(https://notion\.so/[a-zA-Z0-9]+\)', processed_text))
    
    logger.info(f"å¤„ç†äº† {original_refs_count} ä¸ªå¼•ç”¨ï¼Œè½¬æ¢äº† {processed_refs_count} ä¸ª Notion å†…é“¾")
    
    return processed_text

def generate_weekly_content(entries):
    """
    æ ¹æ®æœ¬å‘¨æ¡ç›®ç”Ÿæˆå‘¨æŠ¥å†…å®¹ï¼Œå¹¶è‡ªåŠ¨åˆ›å»ºå†…é“¾å¼•ç”¨
    
    å‚æ•°ï¼š
    entries (list): æœ¬å‘¨ Notion é¡µé¢å¯¹è±¡åˆ—è¡¨
    
    è¿”å›ï¼š
    str: æ ¼å¼åŒ–çš„å‘¨æŠ¥å†…å®¹ï¼ŒåŒ…å«å†…é“¾å¼•ç”¨
    """
    content = []
    content.append("# æœ¬å‘¨å†…å®¹æ€»ç»“\n")
    
    # æŒ‰æ—¥æœŸåˆ†ç»„
    entries_by_date = {}
    for entry in entries:
        # è·³è¿‡å‘¨æŠ¥æœ¬èº«
        if "Tags" in entry["properties"] and any(tag.get("name") == "å‘¨æŠ¥" 
                                               for tag in entry["properties"]["Tags"].get("multi_select", [])):
            continue
            
        # è·å–æ¡ç›®åˆ›å»ºæ—¥æœŸ
        created_date = None
        if "Created" in entry["properties"] and entry["properties"]["Created"].get("date"):
            date_str = entry["properties"]["Created"]["date"].get("start")
            if date_str:
                created_date = date_str.split("T")[0]  # ä»…ä¿ç•™æ—¥æœŸéƒ¨åˆ† YYYY-MM-DD
        
        if not created_date:
            created_date = "æœªçŸ¥æ—¥æœŸ"
        
        if created_date not in entries_by_date:
            entries_by_date[created_date] = []
        
        entries_by_date[created_date].append(entry)
    
    # æŒ‰æ—¥æœŸæ’åº
    for date in sorted(entries_by_date.keys()):
        content.append(f"## {date}\n")
        
        # æ·»åŠ æ¯ä¸ªæ¡ç›®çš„æ‘˜è¦å’Œå†…é“¾
        for entry in entries_by_date[date]:
            # è·å–æ¡ç›®æ ‡é¢˜
            title = "æ— æ ‡é¢˜"
            if "Name" in entry["properties"] and entry["properties"]["Name"].get("title"):
                title_objects = entry["properties"]["Name"]["title"]
                if title_objects and "plain_text" in title_objects[0]:
                    title = title_objects[0]["plain_text"]
                elif title_objects and "text" in title_objects[0] and "content" in title_objects[0]["text"]:
                    title = title_objects[0]["text"]["content"]
            
            # è·å–æ¡ç›®æ‘˜è¦
            summary = ""
            if "Summary" in entry["properties"] and entry["properties"]["Summary"].get("rich_text"):
                summary_objects = entry["properties"]["Summary"]["rich_text"]
                if summary_objects and "plain_text" in summary_objects[0]:
                    summary = summary_objects[0]["plain_text"]
                elif summary_objects and "text" in summary_objects[0] and "content" in summary_objects[0]["text"]:
                    summary = summary_objects[0]["text"]["content"]
            
            # å°è¯•è·å–å†…å®¹å—ä»¥æå–æ›´å¤šè¯¦ç»†ä¿¡æ¯
            try:
                page_content = notion.blocks.children.list(block_id=entry["id"])
                content_text = extract_notion_block_content(page_content.get("results", []))
                
                # å¦‚æœæå–åˆ°å†…å®¹ï¼Œä½¿ç”¨å†…å®¹çš„å‰ä¸€éƒ¨åˆ†ä½œä¸ºæ‘˜è¦å±•ç¤º
                if content_text and not summary:
                    summary = truncate_text(content_text, 150)  # é™åˆ¶æ‘˜è¦é•¿åº¦
            except Exception as e:
                logger.warning(f"æå–é¡µé¢å†…å®¹æ—¶å‡ºé”™ï¼š{e}")
            
            # æˆªæ–­æ‘˜è¦
            if len(summary) > 150:
                summary = summary[:147] + "..."
            
            # ç”ŸæˆåŒ…å«å†…é“¾çš„æ‘˜è¦è¡Œ
            page_id = entry["id"]
            
            # ä½¿ç”¨ ref: æ ¼å¼ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨ process_notion_references å¤„ç†
            content.append(f"- [{title}](ref:{page_id}): {summary}")
        
        content.append("")  # æ·»åŠ ç©ºè¡Œåˆ†éš”ä¸åŒæ—¥æœŸçš„å†…å®¹
    
    # æ·»åŠ ç»“å°¾ï¼Œç­‰å¾… AI ç”Ÿæˆçš„æ€»ç»“
    content.append("# AI å‘¨æŠ¥æ€»ç»“\n")
    content.append("_ä»¥ä¸‹å†…å®¹ç”± AI è‡ªåŠ¨ç”Ÿæˆ_\n")
    
    return "\n".join(content)

def extract_notion_block_content(blocks):
    """
    ä» Notion å—ä¸­æå–æ–‡æœ¬å†…å®¹
    
    å‚æ•°ï¼š
    blocks (list): Notion å—åˆ—è¡¨
    
    è¿”å›ï¼š
    str: æå–çš„æ–‡æœ¬å†…å®¹
    """
    content = []
    
    for block in blocks:
        block_type = block.get("type")
        if not block_type:
            continue
            
        block_data = block.get(block_type)
        if not block_data:
            continue
            
        # å¤„ç†ä¸åŒç±»å‹çš„å—
        if block_type == "paragraph":
            text = extract_rich_text(block_data.get("rich_text", []))
            if text:
                content.append(text)
        elif block_type in ["heading_1", "heading_2", "heading_3"]:
            text = extract_rich_text(block_data.get("rich_text", []))
            if text:
                # æ·»åŠ æ ‡é¢˜æ ‡è®°
                prefix = "#" * int(block_type[-1])
                content.append(f"{prefix} {text}")
        elif block_type == "bulleted_list_item":
            text = extract_rich_text(block_data.get("rich_text", []))
            if text:
                content.append(f"- {text}")
        elif block_type == "numbered_list_item":
            text = extract_rich_text(block_data.get("rich_text", []))
            if text:
                content.append(f"1. {text}")  # ç®€åŒ–å¤„ç†ï¼Œæ‰€æœ‰é¡¹ç›®éƒ½ç”¨ 1.
        elif block_type == "quote":
            text = extract_rich_text(block_data.get("rich_text", []))
            if text:
                content.append(f"> {text}")
        elif block_type == "callout":
            text = extract_rich_text(block_data.get("rich_text", []))
            if text:
                icon = ""
                if "icon" in block_data and "emoji" in block_data["icon"]:
                    icon = block_data["icon"]["emoji"] + " "
                content.append(f"> {icon}{text}")
        elif block_type == "code":
            text = extract_rich_text(block_data.get("rich_text", []))
            language = block_data.get("language", "")
            if text:
                content.append(f"```{language}\n{text}\n```")
                
    return "\n".join(content)

def extract_rich_text(rich_text):
    """
    ä»å¯Œæ–‡æœ¬æ•°ç»„ä¸­æå–çº¯æ–‡æœ¬
    
    å‚æ•°ï¼š
    rich_text (list): Notion å¯Œæ–‡æœ¬å¯¹è±¡åˆ—è¡¨
    
    è¿”å›ï¼š
    str: æå–çš„çº¯æ–‡æœ¬
    """
    if not rich_text:
        return ""
        
    return "".join([rt.get("plain_text", "") for rt in rich_text])

def create_auto_weekly_report():
    """
    è‡ªåŠ¨åˆ›å»ºåŒ…å«æœ¬å‘¨æ‰€æœ‰æ¡ç›®çš„å‘¨æŠ¥
    
    è¿”å›ï¼š
    str: åˆ›å»ºçš„å‘¨æŠ¥é¡µé¢ URL
    """
    # è·å–æœ¬å‘¨æ—¥æœŸèŒƒå›´
    today = datetime.now()
    start_of_week = today - timedelta(days=today.weekday())
    end_of_week = start_of_week + timedelta(days=6)
    week_number = today.isocalendar()[1]
    
    # åˆ›å»ºå‘¨æŠ¥æ ‡é¢˜
    title = f"å‘¨æŠ¥ {today.year} ç¬¬{week_number}å‘¨ ({start_of_week.strftime('%m.%d')}-{end_of_week.strftime('%m.%d')})"
    
    # è·å–æœ¬å‘¨æ¡ç›®
    entries = get_weekly_entries(days=7)
    
    # ç”Ÿæˆå‘¨æŠ¥å†…å®¹
    content = generate_weekly_content(entries)
    
    # åˆ›å»ºå‘¨æŠ¥
    report_url = create_weekly_report(title, content)
    
    logger.info(f"æˆåŠŸåˆ›å»ºå‘¨æŠ¥ï¼š{title} ({report_url})")
    return report_url

def add_to_todo_database(content, created_at=None):
    """
    å°†å¾…åŠäº‹é¡¹æ·»åŠ åˆ° Notion å¾…åŠäº‹é¡¹æ•°æ®åº“
    
    å‚æ•°ï¼š
    content (str): å¾…åŠäº‹é¡¹å†…å®¹
    created_at (datetime): åˆ›å»ºæ—¶é—´
    
    è¿”å›ï¼š
    str: åˆ›å»ºçš„é¡µé¢ ID
    """
    if not NOTION_TODO_DATABASE_ID:
        logger.error("æœªè®¾ç½®å¾…åŠäº‹é¡¹æ•°æ®åº“ ID")
        raise ValueError("æœªè®¾ç½®å¾…åŠäº‹é¡¹æ•°æ®åº“ ID")
    
    if not created_at:
        created_at = datetime.now()
    
    # æˆªå–æ ‡é¢˜
    title = truncate_text(content, 100)
    
    try:
        new_page = notion.pages.create(
            parent={"database_id": NOTION_TODO_DATABASE_ID},
            properties={
                "Name": {
                    "title": [{"text": {"content": title}}]
                },
                "Status": {
                    "select": {"name": "å¾…åŠ"}
                },
                "Priority": {
                    "select": {"name": "ä¸­"}
                },
                "Created": {
                    "date": {"start": created_at.isoformat()}
                }
            },
            children=[
                {
                    "object": "block",
                    "paragraph": {
                        "rich_text": [{"text": {"content": content}}]
                    }
                }
            ]
        )
        logger.info(f"æˆåŠŸåˆ›å»ºå¾…åŠäº‹é¡¹ï¼š{new_page['id']}")
        return new_page['id']
    
    except Exception as e:
        logger.error(f"åˆ›å»ºå¾…åŠäº‹é¡¹æ—¶å‡ºé”™ï¼š{e}")
        raise

def get_existing_dois():
    """
    ä» Notion è®ºæ–‡æ•°æ®åº“ä¸­è·å–æ‰€æœ‰å·²å­˜åœ¨çš„ DOI
    
    è¿”å›ï¼š
    set: å·²å­˜åœ¨çš„ DOI é›†åˆ
    """
    if not NOTION_PAPERS_DATABASE_ID:
        logger.error("æœªè®¾ç½®è®ºæ–‡æ•°æ®åº“ ID")
        return set()
    
    try:
        # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦æœ‰ DOI å­—æ®µ
        db_info = notion.databases.retrieve(database_id=NOTION_PAPERS_DATABASE_ID)
        if "DOI" not in db_info.get('properties', {}):
            logger.warning("è®ºæ–‡æ•°æ®åº“ä¸­æ²¡æœ‰ DOI å­—æ®µï¼Œæ— æ³•æ£€æŸ¥é‡å¤")
            return set()
        
        # æŸ¥è¯¢æ‰€æœ‰æ¡ç›®
        existing_dois = set()
        start_cursor = None
        has_more = True
        
        while has_more:
            response = notion.databases.query(
                database_id=NOTION_PAPERS_DATABASE_ID,
                start_cursor=start_cursor,
                page_size=100,  # æ¯é¡µæœ€å¤šè·å– 100 æ¡
                filter={
                    "property": "DOI",
                    "rich_text": {
                        "is_not_empty": True
                    }
                }
            )
            
            # æå– DOI
            for page in response["results"]:
                if "DOI" in page["properties"]:
                    rich_text = page["properties"]["DOI"].get("rich_text", [])
                    if rich_text and "plain_text" in rich_text[0]:
                        doi = rich_text[0]["plain_text"].strip().lower()
                        if doi:
                            existing_dois.add(doi)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¤šæ•°æ®
            has_more = response.get("has_more", False)
            start_cursor = response.get("next_cursor")
            
            if has_more:
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.5)
        
        logger.info(f"ä» Notion ä¸­è·å–åˆ° {len(existing_dois)} ä¸ªå·²åŒæ­¥çš„ DOI")
        return existing_dois
    
    except Exception as e:
        logger.error(f"è·å–å·²å­˜åœ¨çš„ DOI æ—¶å‡ºé”™ï¼š{e}")
        return set()

def add_to_papers_database(title, analysis, created_at=None, pdf_url=None, metadata=None, zotero_id=None):
    """
    å°†è®ºæ–‡åˆ†ææ·»åŠ åˆ°è®ºæ–‡æ•°æ®åº“
    
    å‚æ•°ï¼š
    title (str): è®ºæ–‡æ ‡é¢˜
    analysis (dict): è®ºæ–‡åˆ†æç»“æœï¼ŒåŒ…å«è¯¦ç»†åˆ†æå’Œç®€æ´æ‘˜è¦
    created_at (datetime): åˆ›å»ºæ—¶é—´
    pdf_url (str): åŸå§‹ PDF URL
    metadata (dict, optional): å…¶ä»–å…ƒæ•°æ®ï¼Œå¦‚ä½œè€…ã€DOIã€å‘è¡¨æ—¥æœŸç­‰
    zotero_id (str, optional): Zotero æ¡ç›® IDï¼Œä½œä¸ºå¤‡ç”¨æ ‡è¯†ç¬¦
    
    è¿”å›ï¼š
    str: åˆ›å»ºçš„é¡µé¢ ID
    """
    if not NOTION_PAPERS_DATABASE_ID:
        logger.error("æœªè®¾ç½®è®ºæ–‡æ•°æ®åº“ ID")
        raise ValueError("æœªè®¾ç½®è®ºæ–‡æ•°æ®åº“ ID")
    
    if not created_at:
        created_at = datetime.now()
    
    # å‡†å¤‡åŸºç¡€å±æ€§
    properties = {
        "Name": {
            "title": [{"text": {"content": title}}]
        },
        "Created": {
            "date": {"start": created_at.isoformat()}
        }
    }
    
    # å¦‚æœæœ‰ Zotero IDï¼Œä½œä¸ºå¤‡ç”¨æ ‡è¯†ç¬¦æ·»åŠ åˆ°å±æ€§ä¸­
    if zotero_id:
        properties["ZoteroID"] = {
            "rich_text": [{"text": {"content": zotero_id}}]
        }
    
    # å¦‚æœæœ‰å…ƒæ•°æ®ï¼Œæ·»åŠ åˆ°å±æ€§ä¸­
    if metadata:
        # å¤„ç†å…ƒæ•°æ®å¹¶æ·»åŠ åˆ°ç›¸åº”çš„å­—æ®µ
        properties = add_paper_metadata_to_properties(properties, metadata)
    
    # å¦‚æœæœ‰ PDF URLï¼Œæ·»åŠ åˆ°å±æ€§ä¸­
    if pdf_url:
        properties["URL"] = {
            "url": pdf_url
        }
    
    # å°†ç®€è¦æ‘˜è¦æ”¾å…¥ Abstract å±æ€§
    if analysis.get('brief_summary'):
        # æˆªæ–­æ‘˜è¦ï¼Œç¡®ä¿ä¸è¶…è¿‡ 2000 ä¸ªå­—ç¬¦ (Notion API é™åˆ¶)
        truncated_summary = analysis.get('brief_summary', '')[:2000]
        properties["Abstract"] = {
            "rich_text": [{"text": {"content": truncated_summary}}]
        }
    
    # å‡†å¤‡å†…å®¹å—
    children = []
    
    # æ·»åŠ æ´å¯Ÿéƒ¨åˆ†
    if analysis.get('insight'):
        children.append({
            "object": "block",
            "callout": {
                "rich_text": [{"text": {"content": analysis.get('insight', '')[:150]}}],
                "icon": {"emoji": "ğŸ’¡"}
            }
        })
    
    # æ·»åŠ è¯¦ç»†åˆ†æå—
    if analysis.get('details'):
        # è½¬æ¢è¯¦ç»†åˆ†æä¸º Notion å—æ ¼å¼
        details_blocks = convert_to_notion_blocks(analysis.get('details', ''))
        children.extend(details_blocks)
    
    try:
        # é¦–å…ˆç¡®ä¿æ•°æ®åº“æœ‰éœ€è¦çš„å±æ€§
        ensure_papers_database_properties()
        
        # åˆ›å»ºé¡µé¢
        new_page = notion.pages.create(
            parent={"database_id": NOTION_PAPERS_DATABASE_ID},
            properties=properties,
            children=children
        )
        logger.info(f"æˆåŠŸåˆ›å»ºè®ºæ–‡åˆ†æï¼š{new_page['id']}")
        return new_page['id']
    
    except Exception as e:
        logger.error(f"åˆ›å»ºè®ºæ–‡åˆ†ææ—¶å‡ºé”™ï¼š{e}")
        raise

def add_paper_metadata_to_properties(properties, metadata):
    """
    å°†è®ºæ–‡å…ƒæ•°æ®æ·»åŠ åˆ° Notion å±æ€§ä¸­
    
    å‚æ•°ï¼š
    properties (dict): ç°æœ‰å±æ€§å­—å…¸
    metadata (dict): å…ƒæ•°æ®å­—å…¸
    
    è¿”å›ï¼š
    dict: æ›´æ–°åçš„å±æ€§å­—å…¸
    """
    # æ·»åŠ ä½œè€…ï¼ˆå¤šé€‰æ–‡æœ¬ï¼‰
    if metadata.get('authors'):
        authors = metadata['authors']
        if isinstance(authors, list) or authors:
            # è½¬ä¸ºé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²
            author_text = ", ".join(authors)
            properties["Authors"] = {
                "rich_text": [{"text": {"content": author_text[:2000]}}]  # Notion API é™åˆ¶
            }
    
    # æ·»åŠ æœŸåˆŠ/å‡ºç‰ˆç‰©ï¼ˆæ–‡æœ¬ï¼‰
    if metadata.get('publication'):
        properties["Publication"] = {
            "rich_text": [{"text": {"content": metadata['publication'][:2000]}}]
        }
    
    # æ·»åŠ å‘å¸ƒæ—¥æœŸ
    if metadata.get('date'):
        try:
            # å°è¯•è§£ææ—¥æœŸå­—ç¬¦ä¸²
            from dateutil.parser import parse
            date_obj = parse(metadata['date'])
            properties["PublishDate"] = {
                "date": {"start": date_obj.strftime('%Y-%m-%d')}
            }
        except:
            # å¦‚æœæ— æ³•è§£æï¼Œä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²
            properties["PublishYear"] = {
                "rich_text": [{"text": {"content": metadata['date'][:100]}}]
            }
    
    # æ·»åŠ  DOI
    if metadata.get('doi'):
        properties["DOI"] = {
            "rich_text": [{"text": {"content": metadata['doi'][:100]}}]
        }
    
    # æ·»åŠ  Zotero é“¾æ¥
    if metadata.get('zotero_link'):
        properties["ZoteroLink"] = {
            "url": metadata['zotero_link']
        }
    
    # æ·»åŠ æ ‡ç­¾ï¼ˆå¤šé€‰ï¼‰
    if metadata.get('tags') and isinstance(metadata['tags'], list):
        multi_select_tags = []
        for tag in metadata['tags'][:10]:  # é™åˆ¶æ•°é‡
            multi_select_tags.append({"name": tag[:100]})  # é™åˆ¶é•¿åº¦
        
        if multi_select_tags:
            properties["Tags"] = {
                "multi_select": multi_select_tags
            }
    
    return properties

def ensure_papers_database_properties():
    """
    ç¡®ä¿è®ºæ–‡æ•°æ®åº“æ‹¥æœ‰æ‰€éœ€çš„æ‰€æœ‰å±æ€§/å­—æ®µ
    ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶ä¼šåˆå§‹åŒ–æ•°æ®åº“ç»“æ„
    """
    try:
        # è·å–å½“å‰æ•°æ®åº“ç»“æ„
        db_info = notion.databases.retrieve(database_id=NOTION_PAPERS_DATABASE_ID)
        existing_properties = db_info.get('properties', {})
        
        # æ£€æŸ¥å¹¶æ·»åŠ ç¼ºå¤±çš„å±æ€§
        required_properties = {
            "Abstract": {"rich_text": {}},
            "Authors": {"rich_text": {}},
            "Publication": {"rich_text": {}},
            "PublishDate": {"date": {}},
            "PublishYear": {"rich_text": {}},  # å¤‡ç”¨å­—æ®µï¼Œå½“æ— æ³•è§£ææ—¥æœŸæ—¶ä½¿ç”¨
            "DOI": {"rich_text": {}},
            "Tags": {"multi_select": {}},
            "ZoteroLink": {"url": {}},
            "URL": {"url": {}}
        }
        
        missing_properties = {}
        for prop_name, prop_config in required_properties.items():
            if prop_name not in existing_properties:
                missing_properties[prop_name] = prop_config
        
        # å¦‚æœæœ‰ç¼ºå¤±çš„å±æ€§ï¼Œæ›´æ–°æ•°æ®åº“ç»“æ„
        if missing_properties:
            logger.info(f"æ­£åœ¨æ·»åŠ ç¼ºå¤±çš„è®ºæ–‡æ•°æ®åº“å±æ€§ï¼š{', '.join(missing_properties.keys())}")
            notion.databases.update(
                database_id=NOTION_PAPERS_DATABASE_ID,
                properties=missing_properties
            )
            logger.info("æ•°æ®åº“ç»“æ„å·²æ›´æ–°")
    
    except Exception as e:
        logger.warning(f"æ£€æŸ¥/æ›´æ–°æ•°æ®åº“ç»“æ„æ—¶å‡ºé”™ï¼š{e}")
        # ç»§ç»­æ‰§è¡Œï¼Œå› ä¸ºè¿™ä¸æ˜¯è‡´å‘½é”™è¯¯

def is_pdf_url(url):
    """
    æ£€æŸ¥ URL æ˜¯å¦ä¸º PDF æ–‡ä»¶é“¾æ¥
    
    å‚æ•°ï¼š
    url (str): è¦æ£€æŸ¥çš„ URL
    
    è¿”å›ï¼š
    bool: å¦‚æœ URL æŒ‡å‘ PDF æ–‡ä»¶åˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
    """
    # URL è·¯å¾„ä»¥ .pdf ç»“å°¾
    if re.search(r'\.pdf(\?.*)?$', url, re.IGNORECASE):
        return True
        
    try:
        # æ£€æŸ¥ HTTP å¤´ä¸­çš„å†…å®¹ç±»å‹
        head_response = requests.head(url, allow_redirects=True, timeout=5)
        content_type = head_response.headers.get('Content-Type', '')
        if 'application/pdf' in content_type.lower():
            return True
            
        # å¦‚æœ HEAD è¯·æ±‚æ²¡æœ‰è¿”å›å†…å®¹ç±»å‹ï¼Œå°è¯• GET è¯·æ±‚çš„å‰å‡ ä¸ªå­—èŠ‚
        if 'content-type' not in head_response.headers:
            response = requests.get(url, stream=True, timeout=5)
            # è¯»å–å‰å‡ ä¸ªå­—èŠ‚æ£€æŸ¥ PDF é­”æ•° %PDF-
            content_start = response.raw.read(5).decode('latin-1', errors='ignore')
            if content_start.startswith('%PDF-'):
                return True
            response.close()
    except Exception as e:
        logger.warning(f"æ£€æŸ¥ PDF URL æ—¶å‡ºé”™ï¼š{e}")
    
    return False

def download_pdf(url):
    """
    ä» URL ä¸‹è½½ PDF æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
    
    å‚æ•°ï¼š
    url (str): PDF æ–‡ä»¶çš„ URL
    
    è¿”å›ï¼š
    tuple: (ä¸‹è½½çš„ PDF æ–‡ä»¶è·¯å¾„ï¼Œæ–‡ä»¶å¤§å° (å­—èŠ‚)), ä¸‹è½½å¤±è´¥åˆ™è¿”å› (None, 0)
    """
    try:
        response = requests.get(url, stream=True, timeout=30)
        if response.status_code == 200:
            # è·å–æ–‡ä»¶å¤§å°
            file_size = int(response.headers.get('content-length', 0))
            logger.info(f"PDF æ–‡ä»¶å¤§å°ï¼š{file_size / (1024 * 1024):.2f} MB")
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            fd, temp_path = tempfile.mkstemp(suffix='.pdf')
            os.close(fd)
            
            # å°†å†…å®¹å†™å…¥ä¸´æ—¶æ–‡ä»¶
            downloaded_size = 0
            with open(temp_path, 'wb') as pdf_file:
                for chunk in response.iter_content(chunk_size=8192):
                    pdf_file.write(chunk)
                    downloaded_size += len(chunk)
            
            logger.info(f"PDF æ–‡ä»¶å·²ä¸‹è½½åˆ°ï¼š{temp_path}")
            return temp_path, downloaded_size or file_size
        else:
            logger.error(f"ä¸‹è½½ PDF å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}")
            return None, 0
    except Exception as e:
        logger.error(f"ä¸‹è½½ PDF æ—¶å‡ºé”™ï¼š{e}")
        return None, 0

def check_paper_exists_in_notion(doi: str) -> bool:
    """
    æ£€æŸ¥è®ºæ–‡æ˜¯å¦å·²å­˜åœ¨äº Notion æ•°æ®åº“ä¸­ï¼ˆé€šè¿‡ DOIï¼‰
    
    å‚æ•°ï¼š
        doi: è®ºæ–‡çš„ DOI
        
    è¿”å›ï¼š
        bool: å¦‚æœè®ºæ–‡å·²å­˜åœ¨åˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
    """
    if not doi:
        return False
    
    try:
        # ä½¿ç”¨å…¨å±€ notion å®¢æˆ·ç«¯ï¼Œè€Œä¸æ˜¯è°ƒç”¨å‡½æ•°
        # notion = get_notion_client() è¿™è¡Œä¼šå¯¼è‡´é”™è¯¯
        
        # æŸ¥è¯¢ Notion æ•°æ®åº“
        response = notion.databases.query(
            database_id=NOTION_PAPERS_DATABASE_ID,
            filter={
                "property": "DOI",
                "rich_text": {
                    "equals": doi
                }
            }
        )
        
        # å¦‚æœæ‰¾åˆ°ç»“æœï¼Œåˆ™è®ºæ–‡å·²å­˜åœ¨
        return len(response.get('results', [])) > 0
    
    except Exception as e:
        logger.error(f"æ£€æŸ¥è®ºæ–‡æ˜¯å¦å­˜åœ¨æ—¶å‡ºé”™ï¼š{e}")
        return False

def ensure_papers_database_properties():
    """ç¡®ä¿è®ºæ–‡æ•°æ®åº“æœ‰æ‰€æœ‰å¿…è¦çš„å±æ€§"""
    try:
        notion = get_notion_client()
        
        # è·å–å½“å‰æ•°æ®åº“ç»“æ„
        database = notion.databases.retrieve(database_id=NOTION_PAPERS_DATABASE_ID)
        current_properties = database.get('properties', {})
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
        needs_update = False
        new_properties = {}
        
        # æ£€æŸ¥å¹¶æ·»åŠ  DOI å±æ€§
        if 'DOI' not in current_properties:
            new_properties['DOI'] = {
                "rich_text": {}
            }
            needs_update = True
        
        # æ£€æŸ¥å¹¶æ·»åŠ å…¶ä»–å¿…è¦å±æ€§ï¼ˆä»¥ä¸‹æ˜¯ç¤ºä¾‹ï¼‰
        required_properties = {
            "Authors": {"rich_text": {}},
            "Publication": {"rich_text": {}},
            "Publication Date": {"date": {}},
            "URL": {"url": {}},
            "Tags": {"multi_select": {}}
        }
        
        for prop_name, prop_config in required_properties.items():
            if prop_name not in current_properties:
                new_properties[prop_name] = prop_config
                needs_update = True
        
        # å¦‚æœéœ€è¦æ›´æ–°ï¼Œæ‰§è¡Œæ›´æ–°æ“ä½œ
        if needs_update:
            logger.info(f"æ­£åœ¨æ›´æ–°è®ºæ–‡æ•°æ®åº“å±æ€§...")
            notion.databases.update(
                database_id=NOTION_PAPERS_DATABASE_ID,
                properties=new_properties
            )
            logger.info(f"è®ºæ–‡æ•°æ®åº“å±æ€§å·²æ›´æ–°")
    
    except Exception as e:
        logger.error(f"ç¡®ä¿è®ºæ–‡æ•°æ®åº“å±æ€§æ—¶å‡ºé”™ï¼š{e}")

def get_existing_zotero_ids() -> set[str]:
    """
    è·å–å·²å­˜åœ¨äº Notion æ•°æ®åº“ä¸­çš„ ZoteroID åˆ—è¡¨
    
    è¿”å›ï¼š
        set[str]: ZoteroID é›†åˆ
    """
    try:
        notion_service = get_notion_service()
        
        # æŸ¥è¯¢æ•°æ®åº“ä¸­æ‰€æœ‰åŒ…å« Zotero ID çš„è®°å½•
        results = []
        has_more = True
        next_cursor = None
        
        # è·å–æ‰€æœ‰é¡µé¢ï¼Œå¯èƒ½éœ€è¦åˆ†é¡µ
        while has_more:
            query_params = {
                "filter": {
                    "property": "ZoteroID",
                    "rich_text": {
                        "is_not_empty": True
                    }
                }
            }
            
            if next_cursor:
                query_params["start_cursor"] = next_cursor
                
            response = notion_service.client.databases.query(
                database_id=notion_service.papers_database_id,
                **query_params
            )
            
            results.extend(response.get("results", []))
            has_more = response.get("has_more", False)
            next_cursor = response.get("next_cursor")
        
        # æå–æ‰€æœ‰ Zotero ID
        zotero_ids = set()
        for page in results:
            try:
                zotero_id_prop = page.get("properties", {}).get("ZoteroID", {})
                if zotero_id_prop and "rich_text" in zotero_id_prop:
                    rich_text = zotero_id_prop.get("rich_text", [])
                    if rich_text:
                        zotero_id = rich_text[0].get("plain_text", "").strip()
                        if zotero_id:
                            zotero_ids.add(zotero_id)
            except Exception as e:
                logger.warning(f"æå– Zotero ID æ—¶å‡ºé”™ï¼š{e}")
                
        logger.info(f"ä» Notion æ•°æ®åº“ä¸­è·å–åˆ° {len(zotero_ids)} ä¸ª Zotero ID")
        return zotero_ids
    
    except Exception as e:
        logger.error(f"è·å–ç°æœ‰ Zotero ID åˆ—è¡¨æ—¶å‡ºé”™ï¼š{e}")
        return set()
